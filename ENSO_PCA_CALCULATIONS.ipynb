{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the available functions are: \n",
      "list_my_functions\n",
      "test_function\n",
      "get_filename\n",
      "get_CMIP_name_list\n",
      "set_new_time_variable\n",
      "get_landsea_mask\n",
      "extract_region\n",
      "mask_out_regions\n",
      "reshape\n",
      "get_PC_components\n",
      "cc_ev\n",
      "dump_into_pickle\n",
      "open_pickle_data\n",
      "uniform_coords\n",
      "zonal_avg\n",
      "Fourier_Analysis\n",
      ":end of list.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import alexas_functions\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from sklearn.decomposition import PCA\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "nn34 = alexas_functions.nn34\n",
    "ep = alexas_functions.ep\n",
    "mc = alexas_functions.mc\n",
    "alexas_functions.list_my_functions()\n",
    "sea100_can= alexas_functions.get_landsea_mask(np.loadtxt('C:\\\\Users\\\\alexa\\\\Documents\\\\RESEARCH\\\\Alexa_Zabaske\\\\Python_Notebooks\\\\datafiles\\\\CanESM2_OceanPercents.txt'), mtype='sea')\n",
    "sea100_mpi = alexas_functions.get_landsea_mask(np.loadtxt('C:\\\\Users\\\\alexa\\\\Documents\\\\RESEARCH\\\\Alexa_Zabaske\\\\Python_Notebooks\\\\datafiles\\\\MPI-ESM_OceanPercents.txt'), mtype='sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########  -----  INIT  -----  ##########\n",
    "num_ensms=1\n",
    "num_of_pcs=3\n",
    "\n",
    "daatype = 'can_ensm'\n",
    "name='CanESM2'\n",
    "sea100_daa = sea100_can\n",
    "\n",
    "# daatype = 'mpi_ensm'\n",
    "# name='MPI-ESM'\n",
    "# sea100_daa = sea100_mpi\n",
    "\n",
    "## specify pca type (global? nh? other?)\n",
    "## specify box type (fixed points)\n",
    "## if going to add a loop, add before extracting region\n",
    "## then correlate with each PRECIP pca\n",
    "## save correlation values into a pandas data frame? \n",
    "## especially the fixed data, like nn34, ep-mc, etc. \n",
    "\n",
    "## to make a heat map, use a fixed box size, and shift it throughout different placements.\n",
    "## calculate the correlation of the sst to the global precip at each box centroid\n",
    "########## INIT ##########\n",
    "\n",
    "###### OUTCOME ######\n",
    "cc_nn34 = np.zeros((4, num_ensms, num_of_pcs))\n",
    "ev_nn34 = np.zeros((4, num_ensms, num_of_pcs))\n",
    "\n",
    "# cc_epmc = np.zeros((4, num_ensms, num_of_pcs))\n",
    "# ev_epmc = np.zeros((4, num_ensms, num_of_pcs))\n",
    "\n",
    "\n",
    "##### BEGIN LOOPING ENSEMBLE MEMBERS\n",
    "for n_e in range(0, num_ensms):\n",
    "\n",
    "    ##### ---- OPEN ts (SST) FILE for single ensemble member\n",
    "    list_of_files_ts = []\n",
    "    filename_ts = alexas_functions.get_filename(daatype, 'historical', 'ts', name, r=n_e)\n",
    "    list_of_files_ts.append(filename_ts)\n",
    "    \n",
    "    if daatype=='mpi_ensm':\n",
    "        list_of_files_ts.append( alexas_functions.get_filename(daatype, 'rcp85', 'ts', name, r=n_e) )\n",
    "        \n",
    "    ts_mon = xr.open_mfdataset(list_of_files_ts)\n",
    "    ts_mon.close()\n",
    "    \n",
    "    ## apply mask to make ts only contain 100% ocean points\n",
    "    ts_mon_sea100 = ts_mon.copy()\n",
    "    ts_mon_sea100['ts'].values = ts_mon_sea100['ts'].values*sea100_daa\n",
    "\n",
    "    ## sample the monthly sst to seasonal means\n",
    "    ts_seas = ts_mon_sea100.resample(time=\"Q-NOV\").mean() \n",
    "    ts_seas = ts_seas.isel(time=(slice(2,-3))) ## lines it up to JJA, SON, DJF, MAM\n",
    "\n",
    "    ## extract nino3.4 region, calculating sst over reagion in return form function\n",
    "    nn34_seas = alexas_functions.extract_region(ts_seas, nn34[0], nn34[1], nn34[2], nn34[3], mean='yes')\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    ##### ----  OPEN PRECIP FILE(s) for single ensemble member\n",
    "    list_of_files_pr = []\n",
    "    filename_pr = alexas_functions.get_filename(daatype, 'historical', 'pr', name, r=n_e)\n",
    "    list_of_files_pr.append(filename_pr)\n",
    "    \n",
    "    if daatype=='mpi_ensm':\n",
    "        list_of_files_pr.append( alexas_functions.get_filename(daatype, 'rcp85', 'pr', name, r=n_e) )    \n",
    "\n",
    "    pr_mon = xr.open_mfdataset(list_of_files_pr)\n",
    "    pr_mon.close()\n",
    "    \n",
    "    print(filename_pr)\n",
    "    \n",
    "    ## save lat and lon size data \n",
    "    latsize=len(pr_mon.lat.values)\n",
    "    lonsize=len(pr_mon.lon.values)\n",
    "    timesize_mon = len(pr_mon.time.values)\n",
    "    #print(latsize, lonsize, timesize_mon)\n",
    "\n",
    "\n",
    "    ## sample the seasonal pr data to seasonal means\n",
    "    pr_seas = pr_mon.resample(time=\"Q-NOV\").mean()\n",
    "    pr_seas = pr_seas.isel(time=(slice(2,-3)))\n",
    "\n",
    "\n",
    "    ## multiply the precip by the latitudinal cosine weights\n",
    "    lat_cos_weights = np.cos(np.deg2rad(pr_seas.lat.values)).reshape((latsize,1)) \n",
    "    pr_seas.pr.values = pr_seas.pr.values *lat_cos_weights\n",
    "\n",
    "    ## INITIALIZE PCA DATA LISTS\n",
    "    \n",
    "    ## -- TS: PC time series for all seasons \n",
    "    pr_PCTS_glob = []\n",
    "\n",
    "    ## -- G: Grid spatial map of PCA for all seasons\n",
    "    pr_PCG_glob = []\n",
    "\n",
    "    ## -- expl: explained variance for all seasons\n",
    "    pr_expl_var_glob = []\n",
    "    \n",
    "    ##### BEGIN LOOPING EACH SEASON\n",
    "    season_nums = np.array([8,11,2,5]) #JJA, SON, DJF, MMA\n",
    "    for s in range(4):\n",
    "\n",
    "        seas=season_nums[s]\n",
    "        pr_1seas = pr_seas.sel(time=pr_seas['time.month'] ==  seas)\n",
    "        pr_glob = pr_1seas\n",
    "\n",
    "        PCG_glob, PCTS_glob, expl_var_glob = get_PC_components(pr_glob, num_of_pcs, opt='all')\n",
    "        pr_PCG_glob.append(PCG_glob)\n",
    "        pr_PCTS_glob.append(PCTS_glob)\n",
    "        pr_expl_var_glob.append(expl_var_glob)\n",
    "\n",
    "\n",
    "        nn34_1seas = nn34_seas.sel( time = nn34_seas['time.month'] == seas )['ts']\n",
    "\n",
    "        #epmc_1seas = epmc_seas.sel( time = epmc_seas['time.month'] == seas )['ts']\n",
    "\n",
    "        for pci in range(num_of_pcs):\n",
    "\n",
    "            cc_nn34[s, n_e-1, pci], ev_nn34[s, n_e-1, pci] = cc_ev(nn34_1seas, pr_PCTS_glob[s][pci])\n",
    "            #cc_epmc[s, n_e-1, pci], ev_epmc[s, n_e-1, pci] = cc_ev(epmc_1seas, pr_PCTS_glob[s][pci])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
